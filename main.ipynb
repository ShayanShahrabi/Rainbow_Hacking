{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Generate Input File Structure\n",
    "\n",
    "The function generates an input file with the following structure:\n",
    "\n",
    "- Each line starts with a user ID in the format `User_i`, where `i` is a random number ranging from 1 to 1 million.\n",
    "- Following each user ID, there is a hash value of random number ranging from 1000 to 10000.\n",
    "\n",
    "Here's an example section of the generated file: \n",
    "```\n",
    "User_392253,74ed65a2d22a92c3b4e013c15ff04d05f4954cd792d9cf56e9a0edad5f914ed1\n",
    "User_852766,5901aee4bc888df51bde5904a4c56d0a68536fb5157e19001973286ceed51354\n",
    "User_513257,abbfc2b6da87b49139e8a13ce2ebf510818cfa6bc42e8cec990d36235dbb99bc\n",
    "User_646094,c8ace20a55c88e4d1fc94009b763c6690efa764f5e6497cc736acf069b1fbc82\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LINES = 1_000_000\n",
    "MIN_VALUE_TO_HASH = 1\n",
    "MAX_VALUE_TO_HASH = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_file(file_name:str, num_lines=100, min_value_to_hash=1000, max_value_to_hash=10_000):\n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Name', 'Hash Value'])  # set the first row of csv file which contains the heads of the colums\n",
    "        for _ in range(num_lines):\n",
    "            name = f'User_{random.randint(1, 1_000_000)}'\n",
    "            num = random.randint(min_value_to_hash, max_value_to_hash)\n",
    "            hash_value = hashlib.sha256(str(num).encode()).hexdigest()\n",
    "            writer.writerow([name, hash_value])\n",
    "\n",
    "# create source file\n",
    "generate_input_file('source.csv', NUM_LINES, MIN_VALUE_TO_HASH, MAX_VALUE_TO_HASH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to break the hash values through a rainbow hacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rainbow_password_hack(hashed_dict, input_file_name, output_file_name):\n",
    "    # create dictionary with the structreu: {hash of a given numeber : number being hashed}\n",
    "    # global hashed_dict\n",
    "    \n",
    "    for num in range(MIN_VALUE_TO_HASH, MAX_VALUE_TO_HASH + 1):\n",
    "        # convert the number to a string and compute its hash value using sha256 algorithm.\n",
    "        hash_value = hashlib.sha256(str(num).encode()).hexdigest()\n",
    "        hashed_dict[hash_value] = num\n",
    "        \n",
    "    with open(input_file_name, 'r') as input_file:\n",
    "        next(input_file)  # skip the first line being the header of the file\n",
    "        lines = input_file.readlines()\n",
    "        \n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "        for line in lines:\n",
    "            name, hash_value = line.strip().split(',')\n",
    "            output_file.write(f\"{name},{hashed_dict[hash_value]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 1.9815020561218262 seconds to finish the task without multithreading\n"
     ]
    }
   ],
   "source": [
    "hashed_dict = {}\n",
    "start_time = time.time()\n",
    "rainbow_password_hack(hashed_dict, 'source.csv', 'result.csv')\n",
    "end_time = time.time()\n",
    "print(f'It took {end_time - start_time} seconds to finish the task without multithreading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multithreading and Batch Proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import hashlib\n",
    "\n",
    "def rainbow_password_hack_multithreaded(hashed_dict, input_file_name, output_file_name):\n",
    "    # Function to process a batch of lines\n",
    "    def process_batch(lines):\n",
    "        for line in lines:\n",
    "            name, hash_value = line.strip().split(',')\n",
    "            output_file.write(f\"{name},{hashed_dict[hash_value]}\\n\")\n",
    "    \n",
    "    # Create a lock to synchronize access to the output file\n",
    "    output_lock = threading.Lock()\n",
    "    \n",
    "    for num in range(MIN_VALUE_TO_HASH, MAX_VALUE_TO_HASH + 1):\n",
    "        # convert the number to a string and compute its hash value using sha256 algorithm.\n",
    "        hash_value = hashlib.sha256(str(num).encode()).hexdigest()\n",
    "        hashed_dict[hash_value] = num\n",
    "        \n",
    "    with open(input_file_name, 'r') as input_file, open(output_file_name, 'w') as output_file:\n",
    "        next(input_file)  # skip the first line being the header of the file\n",
    "        lines = input_file.readlines()\n",
    "        \n",
    "        # Determine the batch size\n",
    "        batch_size = 100  # Adjust this value to find an optimal batch size\n",
    "        \n",
    "        # Create a list to hold the thread objects\n",
    "        threads = []\n",
    "        \n",
    "        for i in range(0, len(lines), batch_size):\n",
    "            # Create a thread for each batch of lines\n",
    "            batch = lines[i:i+batch_size]\n",
    "            t = threading.Thread(target=process_batch, args=(batch,))\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "        \n",
    "        # Wait for all threads to finish\n",
    "        for t in threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2.671334981918335 seconds to finish the task with multithreading\n"
     ]
    }
   ],
   "source": [
    "hashed_dict_2 = {}\n",
    "start_time = time.time()\n",
    "rainbow_password_hack_multithreaded(hashed_dict_2, 'source.csv', 'result.csv')\n",
    "end_time = time.time()\n",
    "print(f'It took {end_time - start_time} seconds to finish the task with multithreading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import hashlib\n",
    "\n",
    "def rainbow_password_hack_parallel(hashed_dict, input_file_name, output_file_name, num_threads):\n",
    "    for num in range(MIN_VALUE_TO_HASH, MAX_VALUE_TO_HASH + 1):\n",
    "        hash_value = hashlib.sha256(str(num).encode()).hexdigest()\n",
    "        hashed_dict[hash_value] = num\n",
    "\n",
    "    with open(input_file_name, 'r') as input_file, open(output_file_name, 'w') as output_file:\n",
    "        next(input_file)  # skip the first line being the header of the file\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "        batch_size = 100\n",
    "        num_lines = len(lines)\n",
    "        num_batches = (num_lines + batch_size - 1) // batch_size\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            # Submit tasks to the executor for parallel processing\n",
    "            futures = []\n",
    "            for i in range(0, num_lines, batch_size):\n",
    "                batch = lines[i:i + batch_size]\n",
    "                future = executor.submit(process_batch, batch, hashed_dict, output_file_name)\n",
    "                futures.append(future)\n",
    "\n",
    "            # Wait for all tasks to complete\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                # Retrieve the result of each task (if needed)\n",
    "                result = future.result()\n",
    "\n",
    "        # All tasks have completed at this point\n",
    "        print(\"All tasks completed!\")\n",
    "\n",
    "def process_batch(lines, hashed_dict, output_file_name):\n",
    "    with open(output_file_name, 'a') as output_file:\n",
    "        for line in lines:\n",
    "            name, hash_value = line.strip().split(',')\n",
    "            output_file.write(f\"{name},{hashed_dict[hash_value]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed!\n",
      "It took 2.7446000576019287 seconds to finish the task with multithreading\n"
     ]
    }
   ],
   "source": [
    "hashed_dict_3 = {}\n",
    "start_time = time.time()\n",
    "rainbow_password_hack_parallel(hashed_dict_3, 'source.csv', 'result.csv', 4)\n",
    "end_time = time.time()\n",
    "print(f'It took {end_time - start_time} seconds to finish the task with multithreading')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
